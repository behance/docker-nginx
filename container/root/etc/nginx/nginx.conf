#############################################################
# Replace nginx configuration directly in this file,
# removing the need to perform error-prone replacements
# at build time.
#
# For run-time replacements, ie, consuming environment vars,
# add to the /etc/cont-init.d/nginx script
#############################################################

# Only set when running with superuser permissions, otherwise causes a warning
# user www-data;

worker_processes auto;

pid /tmp/.nginx/nginx.pid;

error_log /dev/stdout warn;

# Number of file descriptors used for nginx
worker_rlimit_nofile 40000;

events {
    # Optimized to serve many clients with each thread, essential for linux
    use epoll;
    # accept as many connections as possible, may flood worker connections if set too low
    multi_accept on;
    # @see http://serverfault.com/questions/209014/how-can-i-observe-what-nginx-is-doing-to-solve-1024-worker-connections-are-n
    worker_connections 3072;
}

http {
    # Doesn't broadcast version level of server software
    server_tokens off;

    # maximum number and size of buffers for large headers to read from client request
    large_client_header_buffers  4 4k;
    # headerbuffer size for the request header from client, its set for testing purpose
    client_header_buffer_size    1k;
    # if the request body size is more than the buffer size, then the entire (or partial) request body is written into a temporary file
    client_body_buffer_size      128k;
    # see: http://nginx.org/en/docs/hash.html
    types_hash_max_size 2048;
    # if client stop responding, free up memory -- default 60
    send_timeout 2;
    # request timed out -- default 60
    client_body_timeout 65;
    # allow the server to close connection on non responding client, this will free up memory
    reset_timedout_connection    on;
    # Sets the maximum number of requests that can be served through one keep-alive connection.
    # After the maximum number of requests are made, the connection is closed.
    keepalive_requests      10000;
    # don't buffer data sent, good for small data bursts in real time
    tcp_nodelay     on;
    # send headers in one piece, its better then sending them one by one
    tcp_nopush on;

    include       mime.types;
    default_type  application/octet-stream;

    log_format main '$remote_addr - $remote_user [$time_local] "$request" '
                    '$status $body_bytes_sent "$http_referer" '
                    '"$http_user_agent" "$http_x_forwarded_for" NGINX_SERVER';

    log_format minimal '$request_method $request_uri $status';

    access_log /dev/stdout main;

    sendfile        on;

    keepalive_timeout  65;

    client_body_temp_path /tmp/.nginx/client_body;
    fastcgi_temp_path /tmp/.nginx/fastcgi_temp;
    proxy_temp_path /tmp/.nginx/proxy_temp;
    scgi_temp_path /tmp/.nginx/scgi_temp;
    uwsgi_temp_path /tmp/.nginx/uwsgi_temp;

    # Everything available is enabled in the container
    include /etc/nginx/sites-available/*;
}
